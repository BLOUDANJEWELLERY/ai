<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gold 3D Estimator</title>
    <style>
        body { font-family: Arial, sans-serif; }
        .container { text-align: center; margin-top: 20px; }
        video { max-width: 100%; margin-top: 20px; }
        canvas { display: none; }
        #3d-canvas { width: 100%; height: 400px; margin-top: 20px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Gold Purity Estimator - 3D Model</h1>
        <video id="video" width="600" height="400" autoplay></video>
        <br>
        <button id="startCapture">Start Capture</button>
        <br><br>
        <button id="processFrames" disabled>Process Frames</button>
        <br><br>
        <div id="3d-canvas"></div>
    </div>

    <!-- Include OpenCV.js and Three.js -->
    <script src="https://docs.opencv.org/4.x/opencv.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>

    <script>
        let video = document.getElementById("video");
        let startCapture = document.getElementById("startCapture");
        let processFrames = document.getElementById("processFrames");
        let frames = [];
        let captureProgress = document.getElementById("captureProgress");
        
        // Initialize the 3D scene with Three.js
        let scene, camera, renderer, mesh;

        function init3DScene() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / 400, 0.1, 1000);
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, 400);
            document.getElementById("3d-canvas").appendChild(renderer.domElement);

            let geometry = new THREE.BoxGeometry(1, 1, 1);
            let material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
            mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);
            
            camera.position.z = 5;

            let animate = function () {
                requestAnimationFrame(animate);
                mesh.rotation.x += 0.01;
                mesh.rotation.y += 0.01;
                renderer.render(scene, camera);
            };
            animate();
        }

        // Start webcam and capture frames
        function startWebcam() {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(function(stream) {
                    video.srcObject = stream;
                    startCapture.disabled = true;
                    processFrames.disabled = false;
                })
                .catch(function(err) {
                    alert("Error accessing webcam: " + err);
                });
        }

        // Capture frames from video
        function captureFrame() {
            let canvas = document.createElement('canvas');
            let context = canvas.getContext('2d');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            frames.push(canvas);
        }

        // Process frames to create 3D model (simplified version)
        function processCapturedFrames() {
            // Placeholder for object detection and 3D reconstruction
            let finalPointCloud = [];

            frames.forEach(frame => {
                let src = cv.imread(frame);
                let dst = new cv.Mat();

                // Convert to grayscale for easier processing
                cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);

                // Apply edge detection (Canny)
                cv.Canny(dst, dst, 100, 200);

                // Find contours (basic object detection)
                let contours = new cv.MatVector();
                let hierarchy = new cv.Mat();
                cv.findContours(dst, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

                // Simple feature extraction (just for demo)
                contours.forEach(contour => {
                    finalPointCloud.push({ x: contour.data32S[0], y: contour.data32S[1], z: contour.data32S[2] });
                });

                // Assuming we have the point cloud, we would now create a 3D model
                // (this part would typically involve more advanced techniques)
                create3DModel(finalPointCloud);
            });

            // Optionally display the 3D model once processing is complete
            render3DModel(finalPointCloud);
        }

        // Create 3D model from the point cloud
        function create3DModel(pointCloud) {
            // This is a placeholder for creating a 3D model
            // Use Three.js or other methods to create a mesh from the point cloud
            let geometry = new THREE.BufferGeometry();
            let vertices = [];

            pointCloud.forEach(point => {
                vertices.push(point.x, point.y, point.z);
            });

            geometry.setAttribute('position', new THREE.Float32BufferAttribute(vertices, 3));
            let material = new THREE.PointsMaterial({ color: 0x888888, size: 0.1 });
            let points = new THREE.Points(geometry, material);

            scene.add(points);
            camera.position.z = 5;
        }

        // Render 3D model using Three.js
        function render3DModel(pointCloud) {
            // Placeholder rendering process for visualizing the 3D model
            let geometry = new THREE.Geometry();
            pointCloud.forEach(point => {
                geometry.vertices.push(new THREE.Vector3(point.x, point.y, point.z));
            });
            let material = new THREE.PointsMaterial({ color: 0xff0000, size: 0.05 });
            let points = new THREE.Points(geometry, material);
            scene.add(points);

            let animate = function () {
                requestAnimationFrame(animate);
                renderer.render(scene, camera);
            };
            animate();
        }

        // Event Listeners
        startCapture.addEventListener("click", startWebcam);
        processFrames.addEventListener("click", function () {
            captureFrame();
            processCapturedFrames();
        });

        // Initialize the 3D scene
        init3DScene();
    </script>
</body>
</html>
